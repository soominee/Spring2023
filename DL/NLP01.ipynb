{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soominee/Spring2023/blob/main/DL/NLP01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìôNatural Language Processing 1** (May 10, May 17)\n",
        "\n",
        "[Online Reference](https://realpython.com/nltk-nlp-python/)\n",
        "\n",
        "May 17: todo\n",
        "\n",
        "+ Create a bew Colab page to do the following. (Name the file as you can recognize)\n",
        "+ Find online story material (Aesop fable)\n",
        "+ Choose two stories with very different characters\n",
        "+ Make 2 wordcloud images (save them on the desktop)\n",
        "+ Save the colab page on your own github repository"
      ],
      "metadata": {
        "id": "go6WboeUbGGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **‚≠ê0. Preview: Wordcloud**\n",
        "[text file](https://raw.githubusercontent.com/MK316/Class_Spring2022/main/RE.ch05.txt)"
      ],
      "metadata": {
        "id": "O2PyFiMUb5U4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uU9KFUR_afDX"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/MK316/Class_Spring2022/main/RE.ch05.txt\"\n",
        "os.system(\"curl \" + url + \" > RE.ch05.txt\")\n",
        "#@markdown üåÄ read a text file in the server: as _text_\n",
        "file = open(\"RE.ch05.txt\")\n",
        "text = file.read().replace(\"\\n\", \" \")\n",
        "file.close()\n",
        "\n",
        "wc = WordCloud().generate(text) \n",
        "plt.imshow(wc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[nltk text](https://realpython.com/nltk-nlp-python/)"
      ],
      "metadata": {
        "id": "afwYuZFVcYjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Wordcloud with your own text: Paste your text\n",
        "\n",
        "#Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Getting text from the user\n",
        "user_text = input(\"Please paste your text here: \")\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(\n",
        "    background_color='white',\n",
        "    width=800,\n",
        "    height=800,\n",
        "    max_words=100\n",
        ").generate(user_text)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GOV1MCkpcCIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **‚≠ê1. Tokenize  by words or sentences**"
      ],
      "metadata": {
        "id": "5q6r-zrzck26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Tokenize by word\n",
        "+ Tokenize by sentence"
      ],
      "metadata": {
        "id": "rbysmLXDc-3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_string = \"My name is Sarah. I live in a big city. I like to read books and play with my cat.\""
      ],
      "metadata": {
        "id": "zEtRz327dUIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set1 = example_string.split()\n",
        "print(set1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2_q5y8fdbV6",
        "outputId": "89c17ebb-3b8a-4b9a-da14-da9d3f581eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My', 'name', 'is', 'Sarah.', 'I', 'live', 'in', 'a', 'big', 'city.', 'I', 'like', 'to', 'read', 'books', 'and', 'play', 'with', 'my', 'cat.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set2 = example_string.split(\".\") #Ïò®Ï†ê Ïò§Î•∏Ï™ΩÏóê ÏûàÎäî Îπà Í≥µÍ∞ÑÏùÑ empty stringÏúºÎ°ú Ï∑®Í∏âÌïòÏó¨ ÎÑ§Î≤àÏß∏Í∞Ä ''Í∞Ä Îê®\n",
        "set2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fymjWldkdlDK",
        "outputId": "bfd9d0ab-2485-42ea-d90e-aededa5f6ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My name is Sarah',\n",
              " ' I live in a big city',\n",
              " ' I like to read books and play with my cat',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip(): Î∂àÌïÑÏöîÌïú Í≤ÉÏùÑ ÏóÜÏï†Îäî Ìï®Ïàò\n",
        "\n",
        "set3 = [s.strip() for s in set2]\n",
        "set3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F2zbbEit9EH",
        "outputId": "2bdad2e1-5e6a-41ef-ed98-405d47ad39c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My name is Sarah',\n",
              " 'I live in a big city',\n",
              " 'I like to read books and play with my cat',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove empty string in a list\n",
        "\n",
        "set4 = [x for x in set3 if x != \"\"] #stringÏùò Í∏∏Ïù¥Í∞Ä 0Î≥¥Îã§ ÌÅ∞ Í≤ΩÏö∞ÏóêÎßå stringÏúºÎ°ú Ï∑®Í∏âÌïòÎùºÎäî ÏùòÎØ∏ #'!='Îäî Î∂àÏùºÏπòÎ•º ÏùòÎØ∏\n",
        "set4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEydoGW3exAV",
        "outputId": "f3af413b-be48-493b-deb9-ca7f7b3f0576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My name is Sarah',\n",
              " 'I live in a big city',\n",
              " 'I like to read books and play with my cat']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using {nltk} library**"
      ],
      "metadata": {
        "id": "-iqiEf84fEHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "RL3joffedE7a"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slist = sent_tokenize(example_string) #ÏßÄÍ∞Ä ÏïåÏïÑÏÑú empty stringÏùÑ Ï†úÍ±∞Ìïú Ï±ÑÎ°ú Î≥ÄÏàò ÏûêÎ¶¨Ïóê Îì§Ïñ¥Í∞ê->[4]ÌïòÎ©¥ empty stringÏù¥ Îú®Îäî Í≤å ÏïÑÎãàÎùº Ïò§Î•òÍ∞Ä Îú∏\n",
        "slist[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DjB_4MibdKyL",
        "outputId": "db98f538-8393-404b-b537-1b1f3907aa1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My name is Sarah.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[sample text to copy](https://raw.githubusercontent.com/MK316/Class_Spring2022/main/RE.ch05.txt)"
      ],
      "metadata": {
        "id": "EglshAFOvHxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mytext=input(\"Paste text: \")\n",
        "slist1 = sent_tokenize(mytext)\n",
        "slist1[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "ssHpYpALvPvX",
        "outputId": "307f7ea6-dc06-4f9b-8284-bdec2ee81606"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste text: A lion, worn out with years, lay stretched upon the ground utterly helpless and drawing his last breath. A boar came up and, to satisfy an ancient grudge, drove at him with his tusks. Next a bull, determined to be revenged on an old enemy, gored him with his horns.  Upon this an ass, seeing that the old lion could thus be treated with impunity, thought that he would show his spite also. He came and threw his heels in the lion's face, whereupon the dying beast exclaimed; \"The insults of the powerful were bad enough; those I could have managed to bear. But to be spurned by so base a creature as thou, the disgrace of nature, is to die a double death.\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2609dcefb5f9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmytext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Paste text: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mslist1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmytext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mslist1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mywords = word_tokenize(mytext)\n",
        "print(len(mywords))\n",
        "mywords[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "hHVZlwGKfPvI",
        "outputId": "94e0b3a8-770c-4c45-c6dd-d9e9d0704c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1154\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'modern'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **‚≠ê2. Filtering stopwords**\n",
        "\n",
        "**Stopwords**\n",
        "\n",
        "Stop words are words that you want to ignore, so you filter them out of your text when you‚Äôre processing it. Very common words like 'in', 'is', and 'an' are often used as stop words since they don‚Äôt add a lot of meaning to a text in and of themselves.\n",
        "\n",
        "Here‚Äôs how to import the relevant parts of NLTK in order to filter out stop words:"
      ],
      "metadata": {
        "id": "zG6VBVgBgYZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sample = \"Sir, I protest. I am not a merry man!\"\n",
        "s1 = word_tokenize(sample); s1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29UKHNzEgk_J",
        "outputId": "f6ce078e-8d7d-41b1-9657-dc69d6a1f32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sir', ',', 'I', 'protest', '.', 'I', 'am', 'not', 'a', 'merry', 'man', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "WrLO329Ag9me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# string.casefold(): to all lower case so that we can compare strings\n",
        "\n",
        "w1 = \"Mary\"\n",
        "w2 = \"susan\"\n",
        "w1.casefold()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7l7CbDWgiA8E",
        "outputId": "37b46787-eb57-45d4-afc2-a638fdfa4924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mary'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuations and stopwords\n",
        "\n",
        "filtered_list = []\n",
        "\n",
        "for word in s1:\n",
        "   if (word.casefold() not in stop_words) & (len(word)>1):\n",
        "        filtered_list.append(word)\n",
        "\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcBLXzehhApl",
        "outputId": "e2ee446b-6bf3-4892-aca5-acac01544b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sir', 'protest', 'merry', 'man']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test wordclouds with / without stopwords \n",
        "\n",
        "[sample text](https://raw.githubusercontent.com/MK316/Spring2023/main/DL/story1.txt)"
      ],
      "metadata": {
        "id": "z2eFuaFKikI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Wordcloud with your own text: Paste your text\n",
        "\n",
        "#Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Getting text from the user\n",
        "user_text = input(\"Please paste your text here: \")\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(\n",
        "    background_color='white',\n",
        "    width=800,\n",
        "    height=800,\n",
        "    max_words=100\n",
        ").generate(user_text)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MX8ECXqYinQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"\"\"\n",
        "Once upon a time, there was a kind and adventurous boy named Jack. Jack loved exploring and going on exciting adventures. One day, Jack decided to go on a hike in the nearby forest. As he was walking, he heard a soft meowing sound.\n",
        "\n",
        "Jack followed the sound and found a small, black kitten. The kitten was scared and alone. Jack picked up the kitten and carried her in his arms. He decided to take her home and give her a warm place to sleep and plenty of food to eat.\n",
        "\n",
        "Jack named the kitten Luna, and she quickly became his best friend. They did everything together, playing in the park, exploring the woods, and snuggling up together to watch movies at night.\n",
        "\n",
        "One day, Jack and Luna went on a hike and got lost. They wandered deeper and deeper into the woods, but they couldn't find their way back. Jack started to worry, but Luna stayed by his side, meowing softly to comfort him.\n",
        "\n",
        "As they continued to wander, they stumbled upon a clearing where an old man was sitting by a campfire. The old man welcomed them and gave them food and water. Jack explained that they were lost, and the old man offered to help them find their way home.\n",
        "\n",
        "The old man took them on a journey through the woods, showing them which paths to take and which to avoid. Finally, they arrived back at Jack's house, safe and sound.\n",
        "\n",
        "From that day forward, Jack and Luna never went on another adventure without the old man's guidance. They were grateful to have each other and to have made a new friend who could help them when they needed it most.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aL_upLvkjOTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = word_tokenize(text1)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "w2 = [w for w in w1 if w.lower() not in stop_words and len(w) > 2]\n",
        "w2"
      ],
      "metadata": {
        "id": "ndzjKw1wjWUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "additional_stopwords = {'one', 'day', 'upon'}\n",
        "\n",
        "# Create a new set of stopwords that includes the default stopwords and the additional ones\n",
        "stop_words = set(stopwords.words('english') + list(additional_stopwords))"
      ],
      "metadata": {
        "id": "eVkOxKq0lady"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = word_tokenize(text1)\n",
        "stop_words = set(stopwords.words('english') + list(additional_stopwords))\n",
        "\n",
        "w2 = [w for w in w1 if w.lower() not in stop_words and len(w) > 2]\n",
        "w2"
      ],
      "metadata": {
        "id": "9Bmku3Tnlu8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tagging Parts of Speech"
      ],
      "metadata": {
        "id": "rkZx3TWano7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "sentence = input(\"Type your sentence: \")\n",
        "mywords = word_tokenize(sentence)\n",
        "nltk.pos_tag(mywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_VTP5gDnqQ1",
        "outputId": "373dbcf3-6c4b-4a94-9216-7ed609119f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type your sentence: My friend is coming to my town.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('My', 'PRP$'),\n",
              " ('friend', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('coming', 'VBG'),\n",
              " ('to', 'TO'),\n",
              " ('my', 'PRP$'),\n",
              " ('town', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('tagsets')\n",
        "# nltk.help.upenn_tagset()"
      ],
      "metadata": {
        "id": "x48z8Nr2n9Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"book\")"
      ],
      "metadata": {
        "id": "9JKdrUK6pNJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.book import *"
      ],
      "metadata": {
        "id": "hdh2czLUpPwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text8.concordance(\"man\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGeYe6pIpeOU",
        "outputId": "4b931cca-a1b2-4668-899e-11865d6151eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 14 of 14 matches:\n",
            " to hearing from you all . ABLE young man seeks , sexy older women . Phone for \n",
            "ble relationship . GENUINE ATTRACTIVE MAN 40 y . o ., no ties , secure , 5 ft .\n",
            "ship , and quality times . VIETNAMESE MAN Single , never married , financially \n",
            "ip . WELL DRESSED emotionally healthy man 37 like to meet full figured woman fo\n",
            " nth subs LIKE TO BE MISTRESS of YOUR MAN like to be treated well . Bold DTE no\n",
            "eeks lady in similar position MARRIED MAN 50 , attrac . fit , seeks lady 40 - 5\n",
            "eks nice girl 25 - 30 serious rship . Man 46 attractive fit , assertive , and k\n",
            " 40 - 50 sought by Aussie mid 40s b / man f / ship r / ship LOVE to meet widowe\n",
            "discreet times . Sth E Subs . MARRIED MAN 42yo 6ft , fit , seeks Lady for discr\n",
            "woman , seeks professional , employed man , with interests in theatre , dining \n",
            " tall and of large build seeks a good man . I am a nonsmoker , social drinker ,\n",
            "lead to relationship . SEEKING HONEST MAN I am 41 y . o ., 5 ft . 4 , med . bui\n",
            " quiet times . Seeks 35 - 45 , honest man with good SOH & similar interests , f\n",
            " genuine , caring , honest and normal man for fship , poss rship . S / S , S / \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[sample text](https://raw.githubusercontent.com/MK316/Class_Spring2022/main/RE.ch05.txt)"
      ],
      "metadata": {
        "id": "x91NNrBRqq3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Define some plain text\n",
        "text = input(\"Paste your text: \")\n",
        "\n",
        "# Tokenize the text into a list of words\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Create an nltk.Text object from the list of tokens\n",
        "text_object = nltk.Text(tokens)\n",
        "\n",
        "# Use the concordance method to find occurrences of the word \"fox\"\n",
        "text_object.concordance(\"be\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jyZ5kjEqcSJ",
        "outputId": "b414bce5-cbd0-4702-d405-68fc24210985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your text: The DNA trail Everybody loves a good story, and when it's finished, this may be the greatest one ever told. It begins in Africa with a group of people. There are perhaps just a few hundred, surviving by hunting animals and gathering fruits, vegetables, and nuts. It ends about 200,000 years later, with their seven billion descendants spread across the Earth.  In between is an exciting tale of survival, movement, isolation, and conquest, most of it occurring before recorded history. Who were those first modern people in Africa? What routes did they take when they left their home continent to expand into Europe and Asia? When and how did humans reach the Americas? For decades, the only proof was found in a small number of scattered bones and artifacts that our ancestors had left behind. In the past 20 years, however, DNA technologies have allowed scientists to find a record of ancient human migrations in the DNA of living people.  Tracing Ancestry in DNA.  \"Every drop of human blood contains a history book written in the language of our genes,\" says population geneticist Spencer Wells. The human genetic code, or genome, is 99.9 percent identical throughout the world. The bulk of our DNA is the same. However, the remainder is responsible for our individual differences -- in eye color or disease risk, for example. On very rare occasions, a small change -- called a mutation -- can occur. This can then be passed down to all of that person's descendants. Generations later, finding that same mutation in two people's DNA indicates that they share the same ancestor. By comparing mutations in many different populations, scientists can trace their ancestral connections.  These ancient mutations are easiest to tract in two places. One is in DNA that is passed from mother to child (called mitochondrial DNA, or mtDNA). The other is in DNA that travels from father to son (known as the Y chromosome, the part of DNA that determines a child will be a boy). By comparing the mtDNA and Y chromosomes of people from various populations, geneticists can get a rough idea of where and when those groups separated in the great migrations around the planet.  Out of Africa  In the mid-1980s, a study compared mtDNA from people around the world. It found that people of African descent had twice as many genetic differences from each other than did others. Because mutations seem to occur at a steady rate over time, scientists concluded that modern humans must have lived in Africa at least twice as long as anywhere else. They now calculate that all living humans maternally descend from a single woman who lived roughly 150,000 years ago in Africa, a \"mitochondrial Eve.\" If geneticists are right, all of humanity is linked to Eve through an unbroken chain of mothers. This Eve was soon joined by \"Y-chromosome Adam,\" the possible genetic father of us all, also from Africa. DNA studies have confirmed that all the people on Earth can trace their ancestry to ancient Africans.  What seems certain is that at a remarkably recent date -- probably between 50,000 and 70,000 years ago -- one small group of people, the ancestors of modern humans outside of Africa, left Africa for western Asia. They either migrated around the wider northern end of the Red Sea, or across its narrow southern opening.  Once in Asia, genetic evidence suggests, the population split. One group stayed temporarily in the Middle East, while the other began a journey that would last tens of thousands of years. Moving a little farther with each new generation, they followed the coast around the Arabian Peninsula, India, and Southeast Asia, all the way to Australia. \"The movement was probably imperceptible,\" says Spencer Wells. \"It was less of a journey and probably more like walking a little farther down the beach to get away from the crowd.\"  Archeological evidence of this 13,000-kilometer migration from Africa to Australia has almost completely vanished. However, genetic traces of the group that made the trip do exist. They have been found in the DNA of indigenous peoples in Malaysia, in Papua New Guinea, and in the DNA of nearly all Australian aborigines. Modern discoveries of 45,000-year-old bodies in Australia, buried at a site called Lake Mungo, provide physical evidence for the theories as well.  People in the rest of Asia and Europe share different but equally ancient mtDNA and Y-chromosome mutations. These mutations show that most are descendants of the group that stayed in the Middle East for thousands of years before moving on. Perhaps about 40,000 years ago, modern humans first advanced into Europe.  Peopling the Americas  About the same time as modern humans pushed into Europe, some of the same group that had paused in the Middle East spread east into Central Asia. They eventually reached as fas as Siberia, the Korean Peninsula, and Japan. Here begins one of the last chapters in the human story -- the peopling of the Americas. Most scientists believe that today's Native Americans descend from ancient Asians who crossed from Siberia to Alaske in the last ice age. At that time, low sea levels would have exposed a land bridge between the continents. Perhaps they -- only a few hundred people -- were travelling along the coast, moving from one piece of land to the next, between a freezing ocean and a wall of ice. \"A coastal route would have been the easiest way in,\" says Wells. \"But it still would have been a hell of a trip.\" Once across, they followed the immense herds of animals into the mainland. They spread to the tip of South America in as little as a thousand years.  Genetic researchers can only tell us the basic outlines of a story of human migration that is more complex than any ever written. Many details of the movements of our ancestors and their countless individual lives can only be imagined. But thanks to genetic researchers -- themselves descendants of mtDNA Eve and Y-chromosome Adam -- we have begun to unlock important secrets about the origins and movements of our ancient ancestors.\n",
            "Displaying 4 of 4 matches:\n",
            " , and when it 's finished , this may be the greatest one ever told . It begin\n",
            "mutation -- can occur . This can then be passed down to all of that person 's \n",
            "t of DNA that determines a child will be a boy ) . By comparing the mtDNA and \n",
            "r countless individual lives can only be imagined . But thanks to genetic rese\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequency list (next lesson)"
      ],
      "metadata": {
        "id": "3-Xgj495ncM1"
      }
    }
  ]
}